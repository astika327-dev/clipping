# ðŸš€ AWS GPU OPTIMIZATION GUIDE

## Overview

AI Video Clipper telah dioptimalkan secara penuh untuk **AWS g4dn instances** dengan NVIDIA T4 GPU (16GB VRAM). Dokumentasi ini menjelaskan semua optimasi yang telah dilakukan.

## ðŸŽ¯ Performance Targets

| Metric                    | Before (CPU) | After (GPU) | Improvement       |
| ------------------------- | ------------ | ----------- | ----------------- |
| Transcription (1hr video) | 30-60 min    | 2-4 min     | **15x faster**    |
| Video Export (per clip)   | 30-60 sec    | 3-5 sec     | **10x faster**    |
| Parallel Exports          | 1-2          | 4-6         | **4x throughput** |
| Total Processing (1hr)    | 60-90 min    | 8-15 min    | **6x faster**     |

## ðŸ”§ GPU Auto-Configuration

Software secara otomatis:

1. **Mendeteksi GPU** - T4, V100, A10G, RTX series
2. **Memilih Profile** - Optimal settings berdasarkan GPU type
3. **Mengkonfigurasi Whisper** - Model, compute type, beam size
4. **Mengkonfigurasi NVENC** - Preset, quality, parallel streams

### Supported GPU Profiles

| GPU         | Instance | Whisper Model | Compute Type | Parallel Exports |
| ----------- | -------- | ------------- | ------------ | ---------------- |
| Tesla T4    | g4dn.\*  | large-v3      | float16      | 4-6              |
| Tesla V100  | p3.\*    | large-v3      | float16      | 6-8              |
| NVIDIA A10G | g5.\*    | large-v3      | float16      | 6-8              |
| RTX 3060    | -        | large-v3      | float16      | 3-4              |
| RTX 4090    | -        | large-v3      | float16      | 6-8              |

## ðŸ“Š Optimal Settings

### Whisper Transcription (Faster-Whisper)

```python
# config.py - Optimal for T4 GPU
FASTER_WHISPER_MODEL = 'large-v3'          # Best accuracy
FASTER_WHISPER_DEVICE = 'cuda'              # GPU acceleration
FASTER_WHISPER_COMPUTE_TYPE = 'float16'     # Optimal for T4
FASTER_WHISPER_BEAM_SIZE = 5                # High accuracy
FASTER_WHISPER_VAD_FILTER = True            # Skip silence (30-50% faster)
FASTER_WHISPER_TEMPERATURE = 0.0            # Deterministic
FASTER_WHISPER_BEST_OF = 5                  # Multiple samples
```

**Speed Comparison (1 hour video):**

- CPU (int8): ~45 minutes
- GPU (float16, beam=1): ~3 minutes
- GPU (float16, beam=5): ~5 minutes â† Our setting (best accuracy)

### Video Export (NVENC)

```python
# config.py - Optimal for T4 GPU
VIDEO_CODEC = 'h264_nvenc'                  # NVIDIA encoder
VIDEO_BITRATE = '4M'                        # High quality
NVENC_PRESET = 'p4'                         # Balanced (p1=fastest, p7=best)
NVENC_TUNE = 'hq'                           # High quality mode
NVENC_QUALITY = 20                          # Excellent quality (0=best)
NVENC_MULTIPASS = 'fullres'                 # 2-pass encoding
NVENC_B_FRAMES = 3                          # Better compression
NVENC_LOOKAHEAD = 20                        # Smart rate control
USE_GPU_FILTERS = True                      # CUDA scaling
MAX_PARALLEL_EXPORTS = 6                    # Parallel streams
```

**NVENC Preset Guide:**
| Preset | Speed | Quality | Use Case |
|--------|-------|---------|----------|
| p1 | âš¡âš¡âš¡âš¡âš¡ | â­â­ | Live streaming |
| p4 | âš¡âš¡âš¡ | â­â­â­â­ | Balanced (default) |
| p7 | âš¡ | â­â­â­â­â­ | Archival quality |

## ðŸ–¥ï¸ AWS Instance Recommendations

### For Standard Use (g4dn.xlarge)

- **Specs**: 4 vCPU, 16GB RAM, 1x T4 (16GB)
- **Cost**: ~$0.526/hour (Singapore)
- **Processing**: ~15 min for 1 hour video
- **Best for**: Single video processing

### For Heavy Use (g4dn.2xlarge)

- **Specs**: 8 vCPU, 32GB RAM, 1x T4 (16GB)
- **Cost**: ~$0.752/hour (Singapore)
- **Processing**: ~12 min for 1 hour video
- **Best for**: Parallel processing, longer videos

### For Production (g5.xlarge)

- **Specs**: 4 vCPU, 16GB RAM, 1x A10G (24GB)
- **Cost**: ~$1.006/hour (Singapore)
- **Processing**: ~10 min for 1 hour video
- **Best for**: Highest quality, fastest processing

## ðŸ”Œ Environment Variables

Copy `.env.aws-optimal` to `.env` for optimal settings:

```bash
# Transcription
FASTER_WHISPER_MODEL=large-v3
FASTER_WHISPER_DEVICE=cuda
FASTER_WHISPER_COMPUTE_TYPE=float16
FASTER_WHISPER_BEAM_SIZE=5

# Video Export
VIDEO_CODEC=h264_nvenc
VIDEO_BITRATE=4M
NVENC_PRESET=p4
NVENC_QUALITY=20
MAX_PARALLEL_EXPORTS=6

# GPU Filters
USE_GPU_FILTERS=true
SCALE_FILTER=scale_cuda
```

## ðŸ“¡ API Endpoints

### GET /api/gpu-stats

Returns real-time GPU statistics:

```json
{
  "available": true,
  "count": 1,
  "gpus": [
    {
      "name": "Tesla T4",
      "total_memory_mb": 15360,
      "free_memory_mb": 12000,
      "utilization": 45,
      "temperature": 55
    }
  ],
  "profile": {
    "name": "Tesla T4",
    "description": "AWS g4dn instance - NVIDIA T4 16GB"
  },
  "config": {
    "whisper_model": "large-v3",
    "whisper_device": "cuda",
    "video_codec": "h264_nvenc"
  }
}
```

### POST /api/gpu-estimate

Estimate processing time:

```json
// Request
{"duration": 3600}  // 1 hour video

// Response
{
  "transcription_minutes": 4.0,
  "analysis_minutes": 1.2,
  "export_minutes": 3.0,
  "total_minutes": 8.2,
  "device": "gpu",
  "gpu_name": "Tesla T4"
}
```

## ðŸ› ï¸ Troubleshooting

### GPU Not Detected

```bash
# Check CUDA installation
nvidia-smi
python -c "import torch; print(torch.cuda.is_available())"
```

### NVENC Not Available

```bash
# Check FFmpeg NVENC support
ffmpeg -encoders | grep nvenc
```

### Out of VRAM

```python
# Reduce parallel exports in config.py
MAX_PARALLEL_EXPORTS = 2

# Or use smaller model
FASTER_WHISPER_MODEL = 'medium'
```

### scale_cuda Filter Not Found

```python
# Fallback to CPU scaling
USE_GPU_FILTERS = False
SCALE_FILTER = 'scale'
```

## ðŸ“ˆ Monitoring

### Real-time GPU Monitoring

```bash
# On the server
watch -n 1 nvidia-smi
```

### API Monitoring

```bash
# Check GPU stats via API
curl http://your-server:5000/api/gpu-stats
```

### Backend Logs

Startup akan menampilkan:

```
============================================================
ðŸŽ¬ AI VIDEO CLIPPER - GPU OPTIMIZED
============================================================
   Whisper Model: large-v3
   Whisper Device: cuda
   Compute Type: float16
   Beam Size: 5
   Video Codec: h264_nvenc
   Video Bitrate: 4M
   NVENC Preset: p4
   Parallel Exports: 6
   GPU Optimizer: âœ… Active
   Batch Processor: âœ… Active
============================================================
```

## ðŸš€ Quick Deploy to AWS

```bash
# 1. Launch g4dn.xlarge instance with Deep Learning AMI
# 2. Clone repo
git clone https://github.com/your-repo/clipping.git
cd clipping/backend

# 3. Copy optimal config
cp .env.aws-optimal .env

# 4. Install dependencies
pip install -r requirements.txt

# 5. Start server
python app.py --production --port 5000
```

## ðŸ“š Files Added/Modified

### New Files

- `backend/gpu_optimizer.py` - GPU detection & auto-configuration
- `backend/batch_processor.py` - Parallel clip export
- `backend/clip_enhancer.py` - Silence removal & vertical format
- `backend/.env.aws-optimal` - Optimal AWS environment config

### Modified Files

- `backend/config.py` - GPU-optimized default settings
- `backend/app.py` - GPU optimizer integration & API endpoints
- `backend/requirements.txt` - Added nvidia-ml-py

---

## ðŸ“± TikTok/Reels Features

### Silence Removal (Jump Cut Style)

Removes dead air/pauses from clips for fast-paced content.

**API Endpoint:**

```bash
POST /api/enhance-clip
{
    "job_id": "video_202501_mp4",
    "filename": "clip_001.mp4",
    "remove_silence": true,
    "vertical_format": null
}
```

**Settings (config.py):**

```python
SILENCE_REMOVAL_ENABLED = True
SILENCE_THRESHOLD_DB = -35      # dB threshold
MIN_SILENCE_TO_REMOVE = 0.4     # Remove pauses > 400ms
MIN_SPEECH_DURATION = 0.2       # Keep speech segments > 200ms
SILENCE_PADDING = 0.05          # 50ms padding around speech
```

### Vertical Format (9:16)

Convert clips to vertical format for TikTok, Reels, Shorts.

**API Endpoint:**

```bash
POST /api/enhance-clip
{
    "job_id": "video_202501_mp4",
    "filename": "clip_001.mp4",
    "remove_silence": false,
    "vertical_format": "9:16",
    "crop_position": "center"    // "left", "right", "center"
}
```

**Available Formats:**
| Format | Resolution | Platforms |
|--------|------------|-----------|
| 9:16 | 1080x1920 | TikTok, Reels, Shorts |
| 4:5 | 1080x1350 | Instagram Feed |
| 1:1 | 1080x1080 | Instagram, Twitter |
| 16:9 | 1920x1080 | YouTube (default) |

### Combined Enhancement

Create TikTok-ready clips with both features:

```bash
POST /api/enhance-clip
{
    "job_id": "video_202501_mp4",
    "filename": "clip_001.mp4",
    "remove_silence": true,
    "vertical_format": "9:16"
}
```

**Output:** `clip_001_nosilence_9x16.mp4`

### Batch Enhancement

Enhance multiple clips at once:

```bash
POST /api/batch-enhance
{
    "job_id": "video_202501_mp4",
    "clips": ["clip_001.mp4", "clip_002.mp4", "clip_003.mp4"],
    "remove_silence": true,
    "vertical_format": "9:16"
}
```

### Get Available Formats

```bash
GET /api/formats

Response:
{
    "aspect_ratios": {
        "9:16": {"width": 1080, "height": 1920, "name": "TikTok/Reels"},
        "4:5": {"width": 1080, "height": 1350, "name": "Instagram Feed"},
        ...
    },
    "silence_removal": {
        "enabled": true,
        "threshold_db": -35,
        "min_silence": 0.4
    }
}
```

---

**Last Updated**: January 2026
**Optimized For**: AWS g4dn (NVIDIA T4 16GB)
